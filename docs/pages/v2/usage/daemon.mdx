# Daemon Mode

_Oura's_ `daemon` mode processes data in the background, without any live output. This mode is used in scenarios where you need to continuously bridge blockchain data with other persistence mechanisms or to trigger an automated process in response to a particular event pattern.

## Start Daemon Mode

To start _Oura_ in _daemon mode_, use the following command:

```
oura daemon
```

Available options:

- `--config`: path of a custom toml configuration file to use. If not specified, configuration will be loaded from `/etc/oura/daemon.toml`.

Example of starting daemon mode with default config file:

```sh
# config will be loaded from /etc/oura/daemon.toml
oura daemon
```

Example of starting daemon mode with a custom config file at `my_config.toml`:

```sh
oura daemon --config my_config.toml
```

## Configuration

The configuration file needs to specify the source, intersect, filters and sink to use in a particular pipeline. The following toml represent the typical skeleton of an _Oura_ config file:

```toml
[source]
type = "X" # the type of source to use

# custom config fields for this source type
foo = "abc"
bar = "xyz"

[intersect]
type = "W" # the type of source intersect chain

[[filters]]
type = "Y" # the type of filter to use

# custom config fields for this filter type
foo = "123"
bar = "789"

[sink]
# the type of sink to use
type = "Z"

# custom config fields for this sink type
foo = "123"
bar = "789"
```

### The `source` section

This section specifies the origin of the data. The special `type` field must always be present and containing a value matching any of the available built-in sources. The rest of the fields in the section will depend on the selected `type`. See the [sources](../sources) section for a list of available options and their corresponding config values.

### The `intersect` section

Advanced options for instructing Oura from which point in the chain to start reading from. You can read more in [intersect advanced](../advanced/intersect_options)

### The `filters` section

This section specifies a collection of filters that are applied in sequence to each event. The special `type` field must always be present and containing a value matching any of the available built-in filters. Notice that this section of the config is an array, allowing multiple filter sections per config file. See the [filters](../filters) section for a list of available options and their corresponding config values.

### The `sink` section

This section specifies the destination of the data. The special `type` field must always be present and containing a value matching any of the available built-in sinks. The rest of the fields in the section will depend on the selected `type`. See the [sinks](../sinks) section for a list of available options.

### Full Example

Here's an example configuration file that uses a Node-to-Node source and output the events into a Kafka sink:

```toml
[source]
type = "N2N"
peers = ["relays-new.cardano-mainnet.iohk.io:3001"]

[intersect]
type = "Tip"

[[filters]]
type = "SplitBlock"

[[filters]]
type = "ParseCbor"

[sink]
type = "Kafka"
brokers = ["127.0.0.1:53147"]
topic = "mainnet"
```
